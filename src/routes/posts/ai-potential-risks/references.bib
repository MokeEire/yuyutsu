
@misc{hendrycks_overview_2023,
	title = {An {Overview} of {Catastrophic} {AI} {Risks}},
	url = {http://arxiv.org/abs/2306.12001},
	doi = {10.48550/arXiv.2306.12001},
	abstract = {Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose catastrophic risks. Although numerous risks have been detailed separately, there is a pressing need for a systematic discussion and illustration of the potential dangers to better inform efforts to mitigate them. This paper provides an overview of the main sources of catastrophic AI risks, which we organize into four categories: malicious use, in which individuals or groups intentionally use AIs to cause harm; AI race, in which competitive environments compel actors to deploy unsafe AIs or cede control to AIs; organizational risks, highlighting how human factors and complex systems can increase the chances of catastrophic accidents; and rogue AIs, describing the inherent difficulty in controlling agents far more intelligent than humans. For each category of risk, we describe specific hazards, present illustrative stories, envision ideal scenarios, and propose practical suggestions for mitigating these dangers. Our goal is to foster a comprehensive understanding of these risks and inspire collective and proactive efforts to ensure that AIs are developed and deployed in a safe manner. Ultimately, we hope this will allow us to realize the benefits of this powerful technology while minimizing the potential for catastrophic outcomes.},
	urldate = {2023-12-08},
	publisher = {arXiv},
	author = {Hendrycks, Dan and Mazeika, Mantas and Woodside, Thomas},
	month = oct,
	year = {2023},
	note = {arXiv:2306.12001 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\markk\\Zotero\\storage\\3RG4GAK4\\Hendrycks et al. - 2023 - An Overview of Catastrophic AI Risks.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\markk\\Zotero\\storage\\G6UWA6HH\\2306.html:text/html},
}

@article{mozur_one_2019,
	chapter = {Technology},
	title = {One {Month}, 500,000 {Face} {Scans}: {How} {China} {Is} {Using} {A}.{I}. to {Profile} a {Minority}},
	issn = {0362-4331},
	shorttitle = {One {Month}, 500,000 {Face} {Scans}},
	url = {https://www.nytimes.com/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html},
	abstract = {In a major ethical leap for the tech world, Chinese start-ups have built algorithms that the government uses to track members of a largely Muslim minority group.},
	language = {en-US},
	urldate = {2023-12-08},
	journal = {The New York Times},
	author = {Mozur, Paul},
	month = apr,
	year = {2019},
	keywords = {Artificial Intelligence, Cameras, China, CloudWalk Technology, Computer Vision, Computers and the Internet, Lee, Kai-Fu, Megvii Technology Ltd, Ministry of Public Security of the People's Republic of China, Minorities, Police, Racial Profiling, SenseTime Technology Development Co Ltd, Surveillance of Citizens by Government, Uighurs (Chinese Ethnic Group), Yitu Technology},
	file = {Snapshot:C\:\\Users\\markk\\Zotero\\storage\\AKI3HGDM\\china-surveillance-artificial-intelligence-racial-profiling.html:text/html},
}

@misc{noauthor_how_nodate,
	title = {How facial recognition is helping {Putin} curb dissent},
	url = {https://www.reuters.com/investigates/special-report/ukraine-crisis-russia-detentions/},
	urldate = {2023-12-08},
}

@article{esvelt_delay_2022,
	title = {Delay, {Detect}, {Defend}: {Preparing} for a {Future} in which {Thousands} {Can} {Release} {New} {Pandemics}},
	url = {https://dam.gcsp.ch/files/doc/gcsp-geneva-paper-29-22},
	language = {en},
	author = {Esvelt, Kevin M},
	year = {2022},
	file = {Esvelt - 2022 - Delay, Detect, Defend Preparing for a Future in w.pdf:C\:\\Users\\markk\\Zotero\\storage\\EQ7GTCYW\\Esvelt - 2022 - Delay, Detect, Defend Preparing for a Future in w.pdf:application/pdf},
}

@article{urbina_dual_2022,
	title = {Dual {Use} of {Artificial} {Intelligence}-powered {Drug} {Discovery}},
	volume = {4},
	issn = {2522-5839},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9544280/},
	doi = {10.1038/s42256-022-00465-9},
	abstract = {An international security conference explored how artificial intelligence (AI) technologies for drug discovery could be misused for de novo design of biochemical weapons. A thought experiment evolved into a computational proof.},
	number = {3},
	urldate = {2023-12-08},
	journal = {Nature machine intelligence},
	author = {Urbina, Fabio and Lentzos, Filippa and Invernizzi, CÃ©dric and Ekins, Sean},
	month = mar,
	year = {2022},
	pmid = {36211133},
	pmcid = {PMC9544280},
	pages = {189--191},
	file = {PubMed Central Full Text PDF:C\:\\Users\\markk\\Zotero\\storage\\EH9FMSE7\\Urbina et al. - 2022 - Dual Use of Artificial Intelligence-powered Drug D.pdf:application/pdf},
}
