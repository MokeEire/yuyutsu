---
layout: post
title: "The AI is getting faster"
description: "Is it going to continue at this pace?"
categories:
  - AI Policy
date: "9th August 2023"
published: true
edit: https://github.com/mokeeire/yuyutsu/blob/master/src/routes/posts/ai-progress/%2Bpage.md
image: https://media.tenor.com/M4njES4jiw4AAAAC/leon-airplane-the-movie.gif
header: https://picsum.photos/id/1083/800/350
---

The history of artificial intelligence is littered with experts' overâ€“ and underestimating how fast its technology will develop.
As part of week 1 of BlueDot's AI Safety course, I studied the development of AI over the past decade and offered a forecast of AI progress in the near future.
I believe we will see some revolutionary advancements in AI over the next 3-5 years but we will only see incremental progress in the next year or two.

## What does AI need to make progress?

### Better algorithms

Algorithms have improved significantly since the success of deep learning, but progress has relied more heavily on the increased availability of computation and data than improvements in models.
One of the most challenging problems in AI is the alignment of these systems with human values.
Improving the "explainability" of the underlying algorithms will be an important advance in AI research, in part because legislators have already latched onto this concept as the basis for regulating the industry.

### More compute

Increasing the computing power of the machines that run AI models has been a crucial driver of progress in AI since deep learning became popular in the early 2010s.
The graph of the Top 500 supercomputers suggests top computers might be due for a significant advance in the near future, though computers towards the bottom of the list (which are still very powerful) are improving much more slowly.
The supercomputer currently ranked #500 is about as powerful as the top supercomputer in 2010.
This could concentrate the priority-setting of AI research in the hands (keyboards?) of a select few supercomputer owners.

### More data

It seems reasonable to assume available data will continue to increase but it is less clear is whether the newly available data is also increasingly _useful_, or at least as useful as past data.
In systems where we are refining data collection and management, the utility of data is likely to improve.
Fields which rely on web-scraped data from the internet may experience a deluge of new content as a result of generative AI use, but this data may not be as valuable.
It may also amplify existing biases in the model by using the model's own output as input data.

## What might slow AI down?

### It has slowed down each time before

AI has historically progressed in leaps and lulls.
If we use history to gauge a base rate for AI progress, we would expect a slower period of progress to follow significant advances.
Considering we are on the tail end of the deep learning revolution, it might be reasonable to expect the next few years to be a quieter period where progress is building towards the next big advance.
However, the huge increase in investment in the industry, combined with the wide availability of data and compute that did not exist in prior periods of AI activity might suggest that this lull, if indeed we are in one, might be shorter than the last.

### Governments might just do something

Another potential stick in the spokes of accelerating AI capabilities is the potential of government intervention.
Based on their relative proactivity in the realm of data privacy, it seems more likely that the European Union will lead the efforts to enforce safety practices in AI development than the US.
US Senate majority Chuck Schumer(?) has also indicated interest to develop legislation, but the US framework appears to prioritize market innovation over the risks to society.
The levers that determine safety and progress in AI development are still ambiguous to legislators, which is a hurdle for drafting effective legislation.
It seems possible that politicians will not act before a catalyzing event provides a clearer example of what to regulate.
Some examples of such catalyzing events that have garnered media attention over the past few years:

- Google employees have leaked memos expressing beliefs that their AI system was sentient, or that AI progress cannot be controlled

- Robots using AI language models told the UN that AI could do a better job governing than humans

I expect that governments around the world will institute some meaningful laws to enforce safe practices in AI development in the next few years.
I am less confident in this belief because I know that I want it to be true.

## References

- [But what is a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) + [Gradient descent, how neural networks learn](https://www.youtube.com/watch?v=IHZwWFHWa-w), Chapters 1-2 from [3Blue1Brown's Neural networks/Deep Learning series](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) (2017)

- [Visualizing the deep learning revolution](https://medium.com/@richardcngo/visualizing-the-deep-learning-revolution-722098eb9c5), by Richard Ngo (2023)

  - AI models are trained using different machine learning tasks, but the way that the systems transfer their training to real-world tasks is not well understood. We need a better understanding of the accuracy and motivations of AI models to ensure they are deployed safely, especially where AI are performing tasks that affect humans at a societal scale.

- [A short introduction to machine learning](https://www.alignmentforum.org/posts/qE73pqxAZmeACsAdF/a-short-introduction-to-machine-learning), by Richard Ngo (2021)

- [The AI Triad and What It Means for National Security Strategy](https://cset.georgetown.edu/wp-content/uploads/CSET-AI-Triad-Report.pdf), a paper from Georgetown's Center for Security and Emerging Technologies written by Ben Buchanan (2020)

- [How ChatGPT Works Technically](https://www.youtube.com/watch?v=bSvTVREwSNw), a video breaking down the processes of ChatGPT, currently the most well known large language model (2023)
